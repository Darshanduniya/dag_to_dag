from airflow import DAG
from airflow.operators.dummy import DummyOperator
from airflow.operators.trigger_dagrun import TriggerDagRunOperator
from airflow.sensors.external_task import ExternalTaskSensor
from datetime import datetime, timedelta

# Define default arguments for the DAG
default_args = {
    'start_date': datetime(2023, 1, 1),
    'retries': 1
}

# Initialize the main DAG
dag = DAG(
    'example_dag_without_with',
    default_args=default_args,
    description='A DAG with TriggerDagRun and ExternalTaskSensor for another DAG',
    schedule_interval='@daily',
    catchup=False
)

# Define the initial tasks in the parent DAG
task1 = DummyOperator(
    task_id='task1',
    dag=dag
)

task2 = DummyOperator(
    task_id='task2',
    dag=dag
)

task3 = DummyOperator(
    task_id='task3',
    dag=dag
)

# Task to trigger another DAG (child DAG)
trigger_another_dag = TriggerDagRunOperator(
    task_id='trigger_another_dag',
    trigger_dag_id='another_dag',  # Replace with the ID of the DAG you want to trigger
    wait_for_completion=False,     # Do not wait here; we’ll use a sensor
    dag=dag
)

# Sensor to monitor the final status of the child DAG (another_dag)
wait_for_another_dag = ExternalTaskSensor(
    task_id='wait_for_another_dag',
    external_dag_id='another_dag',             # ID of the child DAG to monitor
    external_task_id=None,                     # Monitor the entire DAG’s completion
    allowed_states=['success', 'failed'],      # Wait until the child DAG finishes
    failed_states=['failed'],                  # Mark as failed if the child DAG fails
    mode='reschedule',
    poke_interval=60,                          # Check every 60 seconds
    timeout=timedelta(hours=1),                # Timeout after 1 hour if no completion
    dag=dag
)

# Define the final task in the parent DAG
task4 = DummyOperator(
    task_id='task4',
    dag=dag
)

# Set up dependencies
task1 >> task2 >> task3 >> trigger_another_dag >> wait_for_another_dag >> task4



from airflow.sensors.external_task import ExternalTaskSensor
from airflow import DAG
from datetime import datetime, timedelta

# Define the DAG (parent DAG)
dag = DAG(
    'example_dag_without_with',
    default_args={'start_date': datetime(2024, 11, 7)},
    schedule_interval=None
)

# Sensor to monitor the final status of the child DAG (another_dag)
wait_for_another_dag = ExternalTaskSensor(
    task_id='wait_for_another_dag',
    external_dag_id='another_dag',             # ID of the child DAG to monitor
    external_task_id=None,                     # Monitor the entire DAG’s completion
    allowed_states=['success', 'running'],     # Accept both success and running states
    failed_states=['failed'],                  # Mark as failed if the child DAG fails
    mode='poke',                               # Use poke mode for continuous checking
    poke_interval=60,                          # Check every 60 seconds
    timeout=timedelta(hours=1),                # Timeout after 1 hour if no completion
    dag=dag
)
